## **Logistic regression**

### **Data wrangling**
```{r}
library(GGally)
library(ggplot2)
library(ggpubr)
library(tidyr)
library(dplyr)
library(magrittr)
library(gmodels)
library(boot)
```

In this section Data wrangling has been done for two data sets retrieved from [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets.html). The R script used for data wrangling can be found [here](https://github.com/melakbet/IODS-project/blob/master/data/create_alc.R)


### **Analysis**



The data setes used in this analysis were retrieved from the UCI Machine Learning Repository.The data sets are intend to apprach student achievement in two secondary education Portuguese schools. The data was collected by using school reports and questionaires that includes data alttributes (student grades, demographic, social and school related features). Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por) (Cortez *et al*. 2008). For this analysis, the original dataset (mat and por) have been modified so that the two separate datasets have been joined. Only students who are answered the questionnaire in both portuguese classe are kept. The final data sets used in this analysis includes a total of 382 observation and 35 attributes. 



```{r}

modified_data= read.table("/home/melak/Open_data/IODS-project/data/modified_data.txt", sep="\t", header=TRUE)

colnames(modified_data)

```

Inorder to study the relationship between high/low alcohol consumption and variables. I chose four variables ("absences", "sex", "goout" and "studytime"). My hypothesis about how each variable is related to alcohol consumption shown below:

- **studytime**: Students who dedicate quite much amount of time in thire study, they don't have time to go out for drinking alchol (studytime and high/low alcohol consumption negatively correlated)

- **sex**: Male students have higher alcohol consumption than female stduents (Male students and high/low alcohol consumption positively correlated)

- **goout**: Those students going out with friends quite frequently consume high alchol than students don't going out. (goout and high/low alcohol consumption positively correlated)

- **absences**: Those students who consume more alachol don't attend class for various reason (e.g hangover, attending party in class time ) (absences and high/low alcohol consumption positively correlated)


<br/>


##### **The distributions of my chosen variables and their relationships with alcohol consumption**
<br/>
**A bar plot for demonstrating the distributions of my chosen  variable**
```{r, fig.width=9, fig.height=6}

my_variables= c("absences", "sex", "goout", "studytime", "high_use")

my_variables_data <- select(modified_data, one_of(my_variables))

colnames(my_variables_data)


gather(my_variables_data) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()



```

<br/>
**A Box plot for demonstrating my chosen variables and their relationships with alcohol consumption**

```{r, fig.width=11, fig.height=8}

g1 <- ggplot(modified_data, aes(x = high_use, y = absences,col=sex))

p1=g1 + geom_boxplot() + ylab("absences") + ggtitle("Student absences by alcohol consumption and sex")

g2 <- ggplot(modified_data, aes(x = high_use, y = goout, col=sex))

p2=g2 + geom_boxplot() + ylab("going out with friends")  + ggtitle("Student who going out with friends by alcohol consumption and sex") 

g3 <- ggplot(modified_data, aes(x = high_use, y = studytime, col=sex))

p3=g3 + geom_boxplot() + ylab("studytime - weekly study time")  + ggtitle("Student who dedicate time to study by alcohol consumption and sex") 

ggarrange(p1, p2, p3 , labels = c("A", "B","C"), ncol = 2, nrow = 2)


```
```{r}
#sex_high_use <- CrossTable(my_variables_data$sex, my_variables_data$high_use)
#goout_high_use <- CrossTable(my_variables_data$goout, my_variables_data$high_use)
#goout_high_use <- CrossTable(my_variables_data$goout, my_variables_data$high_use)
#studytime_high_use <- CrossTable(my_variables_data$studytime, my_variables_data$high_use)
```
<br/>
To statistically explore the relationship between my chosen variable and high/low alcohol consumption variable logistic regression moded was build using the R function `glm()`. To 

```{r}

m <- glm(high_use ~  absences + sex +  goout + studytime , data = modified_data, family = "binomial")


```
<br/>
Inorder to be able to interpret the fitted model in detail, the summary, coefficients and confidence intervals of the fitted model are calculated as shown below.
```{r}




summary(m)

coef(m)

OR <- coef(m) %>% exp
CI <- confint(m) %>% exp
cbind(OR,CI)

```

<br/>
As shown above all the four variables are statistically significant. *goout* has the lowest p-value suggesting a strong association of going out with friends and high/low alcohol consumption. The positive coefficient for *goout* predictor suggests that all other variables being equal, going out with friends increase alchol consumption. In the logit model, the response variable is log odds: $ln(odds) = ln(p/(1-p)) =\alpha+ \beta*x_1 + \beta*x_2 + … + \beta*x_n$. A unit increase in going out with friends increase the log odds by 0.72677. The variable *absences* and *sex* have also lowest p-vlaue 0.000499 and 0.003242, respectively. The positive coefficient for *absences*  suggests that all other variables being equal, a unit  increase in the *absences* increase  alchol consumption. A unit increase in absences increase the log odds by 0.07811. *sex* is also the ohter signifcant value with p-value (0.003242) and suggesting association of the sex of the student with high\\low alchol consumption. The positive coefficient for *sex* suggests that all other variables being equal, the male students are high likely alchol consumption. The male student inccrease the log odds by 0.78173. *studytime* is also the other siginficant variable and the negative coefficient for this variable suggests that all other variables being equal, a unit increase in *studytime* reduces the alchol consumption.A unit increase in studytime reduces the log odds by by 0.42116.

The ratio of expected “success” to “failures” defined as odds: p/(1-p). Odds are an alternative way of expressing probabilities. Higher odds corresponds to a higher probability of success when OR > 1. The exponents of the coefficients of a logistic regression model interpreted as odds ratios between a unit change (vs no change) in the corresponding explanatory variable. The exponents of *goout* predector coefficient is 2.06838526 and this suggests a unit change in the goout while  all other the variables being equal, the odd ratio is 2.06838526. The exponents of *sex* predector coefficient is 2.18525582 and this suggests a unit change in the sex while  all other the variables being equal, the odd ratio is 2.18525582. In simlar way, The exponents of *absences* predector coefficient is 1.08123884 and this suggests a unit change in the *absences* while  all other the variables being equal, the odd ratio is 1.08123884. The exponents of *studytime* predector coefficient is 1.08123884 and this suggests a unit change in the *studytime* while  all other the variables being equal, the odd ratio is 0.65628388.  Hence odds ratio for the significant *goout, sex and absences*  variables  are 2.06838526, 2.1852558 and 1.08123884 respectively. It means that *goout, sex and absences* increase high alcohol consumption by the factor of around 2.07, 2.19 and 1.08. Whereas the odds ratio for *studytime* is 0.65628388 and it suggests that *studytime* decreases high alchol consumption.





##### **Predictive power of the model**

```{r}
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'modified_data'

modified_data <- mutate(modified_data, probability = probabilities)

# use the probabilities to make a prediction of high_use

modified_data <- mutate(modified_data, prediction = probability>0.5)

table(high_use = modified_data$high_use, prediction = modified_data$prediction)

```

```{r}
# the logistic regression model m and dataset alc (with predictions) are available

# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(modified_data$high_use, modified_data$probability)

# K-fold cross-validation

cv <- cv.glm(data = modified_data, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]

```