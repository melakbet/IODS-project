## **Dimensionality reduction techniques**

```{r}
#install.packages("FactoMineR")
library(GGally)
library(ggplot2)
library(tidyr)
library(dplyr)
library(corrplot)
library(ggpubr)
library(magrittr)
library(boot)
library(knitr)
library(kableExtra)
library(FactoMineR)
```

```{r}
human<-read.table("data/human.csv")
str(human)
dim(human)

```
<br/>
This week, I am dealing with “human” data which is generated by combing two dataset "Human development” and “Gender inequality". The original data "Human development” and “Gender inequality" originated from the United Nations Development Programme (UNDP) and additional information about the data  can be found [[1]](http://hdr.undp.org/en/content/human-development-index-hdi) and [[2]](http://hdr.undp.org/sites/default/files/hdr2015_technical_notes.pdf). Before combing the two dataset, “Gender inequality” data was mutated by creating two new variables. The first new variable created is the ratio of Female and Male populations with secondary education in each country. (i.e. edu2F / edu2M). The second new variable is the ratio of labour force participation of females and males in each country (i.e. labF / labM). Using the variable Country as the identifier, the two datasets join together. After combing the dataset further modified, by excluding unneeded variables, removing all rows with missing value and keeping observations which related to countries. Finally the human dataset have 155 observations and 8 variables. All the eight variables are continues variable.


<br/>

```{r}
human_summary= do.call(cbind, lapply(human, summary))

kable(human_summary,"html", caption="human data summary table") %>%   kable_styling(bootstrap_options ="condensed",  font_size = 14, full_width = F) %>% column_spec(1:1, bold = T,color = "white", background = "green") %>% row_spec(0, bold = T,  color = "white", background = "green")

```

__Visualizing the scatter plot matrix and examining the correltion between human data variables__

<br/>
```{r, fig.width=13, fig.height=10}

p1=ggpairs(human,title="scatter plot matrix with correlation") 
p1 + theme(plot.title = element_text(size = rel(2)))

```
<br/>
The above scatter plot matrix indicates that some of the variables are skewed: for example the variables GIN, Mat.Mor and Ado.Birth are positively skewed. Whereas, Life.Exp and Labo.FM are negatively skewed. From the scatter plot matrix we can also see that the variables Edu2.FM and Edu.Exp are relatively follow normal distribution.

<br/>

```{r, fig.width=11, fig.height=9}

cor_matrix<-cor(human) %>% round(digits=2)

# visualize the correlation matrix

corrplot(cor_matrix, method="circle", type = "lower", cl.pos = "b", tl.col="black", tl.pos = "d", tl.cex = 1.2,title="Correlations plot",mar=c(0,0,1,0))
```

The above correlation plot shows the relationships between variables. The correlation plot is a colored representation of the human data correlation value where the values are represented as different colors. The correlation values are ranging from red to blue (-1 to 1) and white is the middle value that is zero. For example adolescent birth rate (Ado.Birth) is positively correlated with maternal mortality ratio which is represented in high intensity blue color circle and the scatter plot displayed a correlation value (0.759)  but negatively correlated (-0.857) with life expectancy at birth (Life.Exp). Similarly, ratio of females and males with secondary education (Edu2.FM) and expected years of schooling (Edu.Exp) are both positively correlated with life expectancy at birth (Life.Exp). On the other hand, there is very little correlation between the ratio of females and males in labour force (Labo.FM) with Edu.Exp and GNI.

<br/>


```{r, fig.width=13, fig.height=11}
pca_human_no_standard <- prcomp(human)
pca_human_no_standard

s_no_standard=summary(pca_human_no_standard)

pca_pr_no_standard <- round(100*s_no_standard$importance[2, ], digits = 1)
pc_lab_no_standard=paste0(names(pca_pr_no_standard), " (", pca_pr_no_standard, "%)")

biplot(pca_human_no_standard, cex = c(0.8, 1), col = c("black", "red"), xlab = pc_lab_no_standard[1], ylab = pc_lab_no_standard[2])
```


<br/>


```{r, fig.width=13, fig.height=11}
pca_human_standard <- prcomp(human,scale. = TRUE)
pca_human_standard
s_standard=summary(pca_human_standard)

pca_pr_standard <- round(100*s_standard$importance[2, ], digits = 1)

pc_lab_standard=paste0(names(pca_pr_standard), " (", pca_pr_standard, "%)")

biplot(pca_human_standard, cex = c(0.8, 1), col = c("black", "red"), xlab = pc_lab_standard[1], ylab = pc_lab_standard[2])
```

<br/>

There is a big difference between the results of PCA with and without standardizing data. As it is explained in the slide "PCA is sensitive to the relative scaling of the original features and assumes that features with larger variance are more important than features with smaller variance". Hence Performing PCA on unstandardized variables will results to large loadings for variables with larger variance.For example:  From the summary table, we can clearly see that among eight variables,  the GIN variable has a large variance. this will lead to dependence of a principal component on the GIN variable with high variance. You can see, first principal component is dominated by a variable GIN.PC1 explains nearly all of the variance (99.99%).

When the variables are scaled, we get a much better representation of variables.The first two principal components explained about ~70% of the variance. The first principal component (PC1) explains 53.% of the variation compared to 100% when the data was not scaled.The second principal component (PC2) explains 16.2% of the variance.

From the standardized PCA plot, we can see that four variables, namely Edu.Exp, Life.Exp, GNU and EDU.FM are positively correlated since the angle between these variables arrows are relatively small, out of which GNU and EDU2.FM have the highest correlation since the angle between these two variables are smallest. Similarly, Parli.F and Labo.FM are also positively correlated and so are the variables Mat.Mor and Ado.Birth. Whereas Parli.F and Labo.FM are almost orthogonal to the other variables and show small correlation value. Furthermore, the plot also shows that Life.Exp and Ado.Birth are least correlated as they are farthest in the plot (notice the large angle between these two variables). From the biplot, we cal also see that Parli.F and Labo.FM are positively correlated to PC2 (i.e they are contributing the direction of PC2). whereas other variables are positively correlated to PC1 (i.e they are contributing the direction of PC1). 



<br/>


The tea data we are dealing in this week exercise comes from comes the R package "FactoMineR". It is data frame with 300 rows and 36 columns.  The data used here came from the survey conducted on a sample of 300 tea consumers.

```{r, fig.width=13, fig.height=10}
data("tea")
str(tea)
dim(tea)
#g1<-gather(tea) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") 
#g1+ geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

summary(tea)

```

Among 36 columns (variables), I choose the following variables:

1. What kind of tea do you consume most often (black, Earl Grey) **Tea**
2. Do you consume tea at home (yes, no) **home**
3. Do you add sugar (yes, no) **sugar**
4. Do you always drink tea (always, not always) **always**
5. Do you drink tea after lunch (yes, no) **lunch**
6. Do you think tea is slimming (yes, no) ** slimming**
7. Does tea have an effect on health (yes, no) **health**
